{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\efons\\anaconda3\\envs\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kmodels as kmk\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>FCU</th>\n",
       "      <th>EPL</th>\n",
       "      <th>EPB</th>\n",
       "      <th>FPL</th>\n",
       "      <th>APL</th>\n",
       "      <th>FPB</th>\n",
       "      <th>OPP</th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>Fz</th>\n",
       "      <th>ADD</th>\n",
       "      <th>Subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054566</td>\n",
       "      <td>0.058537</td>\n",
       "      <td>0.062743</td>\n",
       "      <td>0.155728</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.070465</td>\n",
       "      <td>-9.259692</td>\n",
       "      <td>-4.447818</td>\n",
       "      <td>-6.536988</td>\n",
       "      <td>0.026819</td>\n",
       "      <td>6.26_0.9_1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.054646</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.062911</td>\n",
       "      <td>0.154414</td>\n",
       "      <td>0.023787</td>\n",
       "      <td>0.021018</td>\n",
       "      <td>0.077124</td>\n",
       "      <td>-9.502468</td>\n",
       "      <td>-4.600985</td>\n",
       "      <td>-6.520491</td>\n",
       "      <td>0.026349</td>\n",
       "      <td>6.26_0.9_1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.057753</td>\n",
       "      <td>0.062681</td>\n",
       "      <td>0.153220</td>\n",
       "      <td>0.023763</td>\n",
       "      <td>0.021220</td>\n",
       "      <td>0.095268</td>\n",
       "      <td>-9.513043</td>\n",
       "      <td>-4.624847</td>\n",
       "      <td>-6.518658</td>\n",
       "      <td>0.026434</td>\n",
       "      <td>6.26_0.9_1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029398</td>\n",
       "      <td>0.056122</td>\n",
       "      <td>0.056917</td>\n",
       "      <td>0.063201</td>\n",
       "      <td>0.157919</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.022113</td>\n",
       "      <td>0.114959</td>\n",
       "      <td>-9.409544</td>\n",
       "      <td>-4.564386</td>\n",
       "      <td>-6.497891</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>6.26_0.9_1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039197</td>\n",
       "      <td>0.057602</td>\n",
       "      <td>0.056416</td>\n",
       "      <td>0.063981</td>\n",
       "      <td>0.163014</td>\n",
       "      <td>0.023785</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.126942</td>\n",
       "      <td>-9.251525</td>\n",
       "      <td>-4.474644</td>\n",
       "      <td>-6.437751</td>\n",
       "      <td>0.026858</td>\n",
       "      <td>6.26_0.9_1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345171</th>\n",
       "      <td>1.950067</td>\n",
       "      <td>0.077327</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>0.070763</td>\n",
       "      <td>0.186818</td>\n",
       "      <td>0.081797</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>0.090759</td>\n",
       "      <td>-4.916051</td>\n",
       "      <td>-5.716611</td>\n",
       "      <td>-12.003086</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>6.53_1.04_1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345172</th>\n",
       "      <td>1.959866</td>\n",
       "      <td>0.077751</td>\n",
       "      <td>0.027808</td>\n",
       "      <td>0.071065</td>\n",
       "      <td>0.191791</td>\n",
       "      <td>0.082448</td>\n",
       "      <td>0.022103</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>-5.248973</td>\n",
       "      <td>-5.937422</td>\n",
       "      <td>-12.067884</td>\n",
       "      <td>0.024120</td>\n",
       "      <td>6.53_1.04_1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345173</th>\n",
       "      <td>1.969666</td>\n",
       "      <td>0.078584</td>\n",
       "      <td>0.027024</td>\n",
       "      <td>0.071566</td>\n",
       "      <td>0.193814</td>\n",
       "      <td>0.083229</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>0.093776</td>\n",
       "      <td>-5.556444</td>\n",
       "      <td>-6.157407</td>\n",
       "      <td>-12.143441</td>\n",
       "      <td>0.023570</td>\n",
       "      <td>6.53_1.04_1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345174</th>\n",
       "      <td>1.979465</td>\n",
       "      <td>0.078977</td>\n",
       "      <td>0.026315</td>\n",
       "      <td>0.071994</td>\n",
       "      <td>0.195077</td>\n",
       "      <td>0.083762</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.086941</td>\n",
       "      <td>-5.809779</td>\n",
       "      <td>-6.380327</td>\n",
       "      <td>-12.206728</td>\n",
       "      <td>0.023072</td>\n",
       "      <td>6.53_1.04_1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345175</th>\n",
       "      <td>1.989264</td>\n",
       "      <td>0.079077</td>\n",
       "      <td>0.025693</td>\n",
       "      <td>0.072354</td>\n",
       "      <td>0.196594</td>\n",
       "      <td>0.084091</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.077667</td>\n",
       "      <td>-6.071978</td>\n",
       "      <td>-6.645673</td>\n",
       "      <td>-12.258107</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>6.53_1.04_1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1345176 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time       FCU       EPL       EPB       FPL       APL       FPB  \\\n",
       "0        0.000000  0.054566  0.058537  0.062743  0.155728  0.023906  0.021142   \n",
       "1        0.009799  0.054646  0.058400  0.062911  0.154414  0.023787  0.021018   \n",
       "2        0.019599  0.054800  0.057753  0.062681  0.153220  0.023763  0.021220   \n",
       "3        0.029398  0.056122  0.056917  0.063201  0.157919  0.023762  0.022113   \n",
       "4        0.039197  0.057602  0.056416  0.063981  0.163014  0.023785  0.023148   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1345171  1.950067  0.077327  0.028705  0.070763  0.186818  0.081797  0.022118   \n",
       "1345172  1.959866  0.077751  0.027808  0.071065  0.191791  0.082448  0.022103   \n",
       "1345173  1.969666  0.078584  0.027024  0.071566  0.193814  0.083229  0.022089   \n",
       "1345174  1.979465  0.078977  0.026315  0.071994  0.195077  0.083762  0.022077   \n",
       "1345175  1.989264  0.079077  0.025693  0.072354  0.196594  0.084091  0.022066   \n",
       "\n",
       "              OPP        Fx        Fy         Fz       ADD         Subject  \n",
       "0        0.070465 -9.259692 -4.447818  -6.536988  0.026819   6.26_0.9_1.06  \n",
       "1        0.077124 -9.502468 -4.600985  -6.520491  0.026349   6.26_0.9_1.06  \n",
       "2        0.095268 -9.513043 -4.624847  -6.518658  0.026434   6.26_0.9_1.06  \n",
       "3        0.114959 -9.409544 -4.564386  -6.497891  0.026648   6.26_0.9_1.06  \n",
       "4        0.126942 -9.251525 -4.474644  -6.437751  0.026858   6.26_0.9_1.06  \n",
       "...           ...       ...       ...        ...       ...             ...  \n",
       "1345171  0.090759 -4.916051 -5.716611 -12.003086  0.024750  6.53_1.04_1.02  \n",
       "1345172  0.095652 -5.248973 -5.937422 -12.067884  0.024120  6.53_1.04_1.02  \n",
       "1345173  0.093776 -5.556444 -6.157407 -12.143441  0.023570  6.53_1.04_1.02  \n",
       "1345174  0.086941 -5.809779 -6.380327 -12.206728  0.023072  6.53_1.04_1.02  \n",
       "1345175  0.077667 -6.071978 -6.645673 -12.258107  0.022634  6.53_1.04_1.02  \n",
       "\n",
       "[1345176 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/LP_Simulations_Formatted.pkl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_into_subjects(df):\n",
    "    subject_names = df['Subject'].unique()\n",
    "    return [df[df['Subject'] == subject] for subject in subject_names]\n",
    "\n",
    "def split_subject_df(subject_df):\n",
    "    # get the time column for the subject\n",
    "    time = subject_df['Time'].values\n",
    "    # get the indices where the time resets to its minimum value\n",
    "    time_splits = np.where(time == time.min())[0]\n",
    "    # split the subject index into events\n",
    "    subject_events = np.split(subject_df.index, time_splits)\n",
    "    # get rid of the empty lists in the list of lists\n",
    "    subject_events = [i for i in subject_events if len(i) > 0]\n",
    "    # return the list of events\n",
    "    return [subject_df.loc[event] for event in subject_events]\n",
    "\n",
    "def sliding_event_df(event_df, window_size, stride):\n",
    "    # get the number of rows in the event\n",
    "    num_rows = event_df.shape[0]\n",
    "    # get the number of windows in the event\n",
    "    num_windows = (num_rows - window_size) // stride + 1\n",
    "    # get the indices of the windows\n",
    "    window_indices = [np.arange(i, i + window_size) for i in range(0, num_windows * stride, stride)]\n",
    "    # return the list of windows\n",
    "    return [event_df.iloc[window] for window in window_indices]\n",
    "\n",
    "class Dataset_LSTM(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, window_size = 50, stride = 10, xcols = ['EPB', 'EPL', 'FPL', 'APL', 'ADD', 'FCU', 'FPB', 'OPP'], ycols = ['Fx','Fy','Fz'], sort_column=['Event','Subject']):\n",
    "        self.df = df\n",
    "        self.xcols = xcols\n",
    "        self.ycols = ycols\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        # get the subjects from the dataframe\n",
    "        subjects = split_df_into_subjects(df)\n",
    "        subject_events = [split_subject_df(subject) for subject in subjects]\n",
    "        # for each event create a sliding window using the window size and stride\n",
    "        subject_event_windows = [[sliding_event_df(event, window_size, stride) for event in subject] for subject in subject_events]\n",
    "        # flatten the list of lists\n",
    "        subject_event_windows = [window for subject in subject_event_windows for event in subject for window in event]\n",
    "        self.x_windows = [window[xcols].values for window in subject_event_windows]\n",
    "        self.y_windows = [window[ycols].values for window in subject_event_windows]\n",
    "        # save X for an LSTM model. the X shape should be (num_windows, window_size, num_features)\n",
    "        self.X = np.array([np.expand_dims(x, axis=0) for x in self.x_windows])\n",
    "        self.X = self.X.reshape(self.X.shape[0], self.X.shape[2], self.X.shape[3])\n",
    "        # save Y for an LSTM model. the Y shape should be (num_windows, window_size, num_features)\n",
    "        self.Y = np.array([np.expand_dims(y, axis=0) for y in self.y_windows])\n",
    "        self.Y = self.Y.reshape(self.Y.shape[0], self.Y.shape[2], self.Y.shape[3])\n",
    "        # save the number of windows\n",
    "        self.num_windows = self.X.shape[0]\n",
    "        # save the number of features\n",
    "        self.num_features = self.X.shape[2]\n",
    "        # save the number of outputs\n",
    "        self.num_outputs = self.Y.shape[2]\n",
    "        # save all the variables we used to the class\n",
    "        self.subjects = subjects\n",
    "        self.subject_events = subject_events\n",
    "        self.subject_event_windows = subject_event_windows\n",
    "        self.sort_column = sort_column\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class Dataset_LSTM_Parallel(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, window_size = 50, stride = 10, xcols = ['EPB', 'EPL', 'FPL', 'APL', 'ADD', 'FCU', 'FPB', 'OPP'], ycols = ['Fx','Fy','Fz'], sort_column=['Event','Subject']):\n",
    "        self.df = dd.from_pandas(df, npartitions=4)\n",
    "        self.xcols = xcols\n",
    "        self.ycols = ycols\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.sort_column = sort_column\n",
    "        \n",
    "        self.df = self.df.map_partitions(split_df_into_subjects, meta=(None,))\n",
    "        self.df = self.df.map_partitions(split_subject_df, meta=(None,))\n",
    "        self.df = self.df.map_partitions(lambda x: [sliding_event_df(event, window_size, stride) for event in x], meta=(None,))\n",
    "        self.df = self.df.flatten()\n",
    "        self.df = self.df.map(lambda x: x[xcols + ycols], meta=(None,))\n",
    "        self.df = self.df.repartition(npartitions=4)\n",
    "        \n",
    "        self.X = da.stack([self.df[xcols].to_dask_array() for _, self.df in self.df.groupby(sort_column)], axis=0)\n",
    "        self.X = self.X.reshape(-1, window_size, len(xcols))\n",
    "        self.Y = da.stack([self.df[ycols].to_dask_array() for _, self.df in self.df.groupby(sort_column)], axis=0)\n",
    "        self.Y = self.Y.reshape(-1, window_size, len(ycols))\n",
    "        \n",
    "        self.num_windows = self.X.shape[0]\n",
    "        self.num_features = self.X.shape[2]\n",
    "        self.num_outputs = self.Y.shape[2]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_windows\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].compute(), self.Y[idx].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def split_df_into_subjects_dask(df):\n",
    "    subject_names = df['Subject'].unique().compute()\n",
    "    return [df[df['Subject'] == subject] for subject in subject_names]\n",
    "\n",
    "def split_subject_df_dask(subject_df):\n",
    "    # get the time column for the subject\n",
    "    time = subject_df['Time'].values.compute()\n",
    "    # get the indices where the time resets to its minimum value\n",
    "    time_splits = np.where(time == time.min())[0]\n",
    "    # split the subject index into events\n",
    "    subject_events = da.split(subject_df.index.compute(), time_splits)\n",
    "    # get rid of the empty lists in the list of lists\n",
    "    subject_events = [i for i in subject_events if len(i) > 0]\n",
    "    # return the list of events\n",
    "    return [subject_df.loc[event] for event in subject_events]\n",
    "\n",
    "def sliding_event_df_dask(event_df, window_size, stride):\n",
    "    # get the number of rows in the event\n",
    "    num_rows = event_df.shape[0].compute()\n",
    "    # get the number of windows in the event\n",
    "    num_windows = (num_rows - window_size) // stride + 1\n",
    "    # get the indices of the windows\n",
    "    window_indices = [da.arange(i, i + window_size) for i in range(0, num_windows * stride, stride)]\n",
    "    # return the list of windows\n",
    "    return [event_df.iloc[window] for window in window_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets split the dataframe into a train and test set using the Subject column. Keep subjects separate during training and testing\n",
    "#df = dd.from_pandas(df, npartitions=4)\n",
    "subject_dfs = split_df_into_subjects(df)\n",
    "train_split = 0.8\n",
    "n_train_subjects = int(len(subject_dfs) * train_split)\n",
    "n_test_subjects = len(subject_dfs) - n_train_subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 414)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test_subjects, n_train_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly pick the subjects to use for training and testing\n",
    "train_subjects_index = np.random.choice(len(subject_dfs), n_train_subjects, replace=False)\n",
    "train_df = dd.concat([subject_dfs[i] for i in train_subjects_index])\n",
    "test_df = dd.concat([subject_dfs[i] for i in range(len(subject_dfs)) if i not in train_subjects_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.compute()\n",
    "test_df = test_df.compute()\n",
    "##train_data = Dataset_LSTM(train_df, sort_column=['Subject'], window_size=100, stride=5)\n",
    "##test_data = Dataset_LSTM(test_df, sort_column=['Subject'], window_size=100, stride=5)\n",
    "\n",
    "train_data = Dataset_LSTM(train_df, sort_column=['Subject'], window_size=100, stride=5)\n",
    "test_data = Dataset_LSTM(df, sort_column=['Subject'], window_size=100, stride=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_df[train_df['Subject']==train_subjects[0]]\n",
    "d.plot(x='Time', y='Fx', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the first 10 samples of data.Y\n",
    "plt.plot(train_data.Y[:10].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,10))\n",
    "ax[0].plot(train_data[1][0])\n",
    "ax[0].set_xlabel('time steps')\n",
    "ax[0].set_ylabel('Mucle Activation')\n",
    "ax[1].plot(train_data[1][1])\n",
    "ax[1].set_xlabel('time steps')\n",
    "ax[1].set_ylabel('Force')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get relu from pytroch\n",
    "from torch.nn import functional as F\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self, n_inputs=8, hidden_size=30, n_outputs=300, n_linear_layers=1, \n",
    "                 layer_size=10, lstm_n_outputs=30):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(n_inputs, hidden_size, batch_first=True)\n",
    "        self.fcs = nn.ModuleList([nn.Linear(layer_size, layer_size) for i in range(n_linear_layers)])\n",
    "        self.layer_size = layer_size\n",
    "        self.n_linear_layers = n_linear_layers \n",
    "        self.lstm_n_outputs = lstm_n_outputs\n",
    "        self.output = nn.Linear(layer_size, n_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        rows = x.shape[0]\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.reshape(rows, -1)\n",
    "        for i, fc in enumerate(self.fcs):\n",
    "            if fc == self.fcs[0]:\n",
    "                if x.shape[1] != int(fc.in_features):\n",
    "                    try:    \n",
    "                        self.fcs[0] = nn.Linear(x.shape[1], self.layer_size)\n",
    "                        x = F.relu(self.fcs[0](x))\n",
    "                    except:\n",
    "                        self.fcs[0] = nn.Linear(x.shape[1], self.layer_size).to('cuda')\n",
    "                        x = F.relu(self.fcs[0](x))\n",
    "                else:\n",
    "                    x = F.relu(fc(x))\n",
    "            else:\n",
    "                x = F.relu(fc(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    " \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm(n_linear_layers=3, n_outputs = len(train_data.Y[0].flatten()), lstm_n_outputs = 3000, layer_size=30).to('cuda')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASS A SAMPLE THROUGH TO FIX THE MODEL DIMENSIONS\n",
    "model(train_data.X)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = kmk.run_Pytorch(model, train_data.X.reshape(-1, 100, 8), train_data.Y, n_epochs=200, batch_size=256, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parity plot\n",
    "pred = model(train_data.X.to('cuda')).detach().cpu().numpy().reshape(-1,1)\n",
    "y = train_data.Y.detach().cpu().numpy().reshape(-1,1)\n",
    "plt.scatter(pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "r2 = r2_score(y, pred)\n",
    "mae = mean_absolute_error(y, pred)\n",
    "mse = mean_squared_error(y, pred)\n",
    "print('r2: ', r2, 'mae: ', mae, 'mse: ', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(test_data.X.to('cuda')).detach().cpu().numpy().reshape(-1,1)\n",
    "y_test = test_data.Y.detach().cpu().numpy().reshape(-1,1)\n",
    "plt.scatter(pred, y_test)\n",
    "r2 = r2_score(y_test, pred)\n",
    "mae = mean_absolute_error(y_test, pred)\n",
    "mse = mean_squared_error(y_test, pred)\n",
    "print('r2: ', r2, 'mae: ', mae, 'mse: ', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a sample of the data\n",
    "n = np.random.randint(0, len(test_data))\n",
    "x_plot = test_data.X[n].detach().cpu().numpy()\n",
    "y_plot = test_data.Y[n].detach().cpu().numpy().reshape(-1, 3)\n",
    "print(y_plot.shape)\n",
    "y_labels = test_data.ycols\n",
    "x_labels = test_data.xcols\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,10))\n",
    "ax[0].plot(x_plot)\n",
    "ax[0].set_xlabel('time steps')\n",
    "ax[0].set_ylabel('Mucle Activation')\n",
    "ax[1].plot(y_plot)\n",
    "    \n",
    "ax[1].set_xlabel('time steps')\n",
    "ax[1].set_ylabel('Force')\n",
    "ax[1].legend(y_labels)\n",
    "#plot the prediction of this sample\n",
    "pred = model(test_data.X[0].to('cuda').unsqueeze(0)).detach().cpu().numpy().reshape(-1, 3)\n",
    "ax[1].plot(pred, '--')\n",
    "# print the mean prediction on the plot\n",
    "pred_mean = np.mean(pred, axis=0)\n",
    "print(pred_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "plot_lstm_prediction(leave_out_df['Subject'].unique()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2c1d3e12e66dc47a0aae61db106152a68be04014ca291cb297471e9102f95b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
